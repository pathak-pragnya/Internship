{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment7_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS2it3qZ2DFO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Input, Bidirectional,Embedding\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN9_VO1LoUiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d8903a-8385-4e2f-dfd7-148e5b360810"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt' , 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LWuoWmkoeQH",
        "outputId": "5413bbdf-ec6b-444d-bb85-cfaf9a28d3eb"
      },
      "source": [
        "text = open(path_to_file , 'rb').read().decode( encoding='utf-8' )\n",
        "\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rn3ocgiokAJ",
        "outputId": "e1ce48b5-efeb-4f42-a2e0-6049961fcbed"
      },
      "source": [
        "print(text[:100])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GajFEBpvooJN",
        "outputId": "c023e357-6fa6-4c8a-d8bf-417addde9648"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ94KiLFpESZ"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(vocabulary = list(vocab),\n",
        "                                            mask_token=None)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaTV0pj1qcnM"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etRk2-2mpaUS"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmEddRsUpdxy",
        "outputId": "85a1798e-5d4a-4831-bb04-fa952389c3d6"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text , 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSCp2G-XqJiv"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxlt-grfqOfh",
        "outputId": "8929d8d8-76fe-4e21-caa4-8927079a08c4"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_20mgH4qTR9"
      },
      "source": [
        "seq_length = 50\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7DPnMMQqn8F",
        "outputId": "249f1b78-de32-4826-a67e-f2273deb500c"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1 , drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' '], shape=(51,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGKZc19pq0aa"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text , target_text"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi0zGo6jrJg_"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_37Aoq0DrPFM"
      },
      "source": [
        "for input_example , target_example in dataset.take(1):\n",
        "  print('Input: ',text_from_ids(input_example).numpy())\n",
        "  print('Target: ',text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c98pCOtKrZzR"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "buffer_size = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(buffer_size)\n",
        "    .batch(batch_size,drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xtbl5i3sWAx"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "embedding_dim = 256\n",
        "\n",
        "rnn_units = 1024"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvzI0JuMei5T"
      },
      "source": [
        "def loss_plot(history):\n",
        "  plt.xlabel(\"Number of Epochs\")\n",
        "  plt.ylabel('Loss', fontsize=16)\n",
        "  plt.plot(history.history['loss'], color='b', label='Training Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skzlh_v4OBtt"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laVnwXASGuqc"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = tf.keras.layers.LSTM(rnn_units,\n",
        "                                   activation='tanh',\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
        "                                   )\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.lstm.get_initial_state(x)\n",
        "    x, mem_states, carry_state = self.lstm(x, initial_state=states, training=training)\n",
        "    states = [mem_states, carry_state]\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x,states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6boINu3LIg1"
      },
      "source": [
        "lstm_model_2 = MyModel(\n",
        "    vocab_size = len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atgSL6nLLn1M"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0pl2n7WJPbi"
      },
      "source": [
        "opt = keras.optimizers.RMSprop(learning_rate=1e-3)\n",
        "lstm_model_2.compile(optimizer=opt, loss=loss)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa0OgPJmJ1Q3"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints_LSTM2'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQFtpxTjJ5tP"
      },
      "source": [
        "epochs = 200"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXPavLuXJ5px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e781c020-a630-48df-ef03-fed924f21c24"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor = 'loss',min_delta=0.001, patience = 10, mode = 'min', verbose = 2)\n",
        "reduce_lr =  ReduceLROnPlateau(monitor='loss', factor=0.1,\n",
        "                              patience=5, min_lr=0.0000001, verbose=2)\n",
        "history_lstm = lstm_model_2.fit(dataset, epochs=epochs, callbacks=[early_stopping, reduce_lr, checkpoint_callback])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 2.1743\n",
            "Epoch 2/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 1.6165\n",
            "Epoch 3/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 1.4473\n",
            "Epoch 4/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 1.3603\n",
            "Epoch 5/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 1.2977\n",
            "Epoch 6/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 1.2426\n",
            "Epoch 7/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 1.1885\n",
            "Epoch 8/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 1.1337\n",
            "Epoch 9/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 1.0760\n",
            "Epoch 10/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 1.0157\n",
            "Epoch 11/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.9533\n",
            "Epoch 12/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.8901\n",
            "Epoch 13/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.8265\n",
            "Epoch 14/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.7661\n",
            "Epoch 15/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.7084\n",
            "Epoch 16/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.6555\n",
            "Epoch 17/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.6078\n",
            "Epoch 18/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.5655\n",
            "Epoch 19/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.5288\n",
            "Epoch 20/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.4983\n",
            "Epoch 21/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.4722\n",
            "Epoch 22/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.4497\n",
            "Epoch 23/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.4315\n",
            "Epoch 24/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.4152\n",
            "Epoch 25/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.4032\n",
            "Epoch 26/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3915\n",
            "Epoch 27/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.3835\n",
            "Epoch 28/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3770\n",
            "Epoch 29/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3703\n",
            "Epoch 30/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3653\n",
            "Epoch 31/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.3606\n",
            "Epoch 32/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.3575\n",
            "Epoch 33/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3550\n",
            "Epoch 34/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3530\n",
            "Epoch 35/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3506\n",
            "Epoch 36/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3491\n",
            "Epoch 37/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3487\n",
            "Epoch 38/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3480\n",
            "Epoch 39/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.3478\n",
            "Epoch 40/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3478\n",
            "Epoch 41/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3471\n",
            "Epoch 42/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.3482\n",
            "Epoch 43/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3472\n",
            "Epoch 44/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3480\n",
            "Epoch 45/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.3487\n",
            "Epoch 46/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.3490\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 47/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.2597\n",
            "Epoch 48/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.2036\n",
            "Epoch 49/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1844\n",
            "Epoch 50/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1753\n",
            "Epoch 51/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1701\n",
            "Epoch 52/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1666\n",
            "Epoch 53/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1642\n",
            "Epoch 54/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1624\n",
            "Epoch 55/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1610\n",
            "Epoch 56/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1598\n",
            "Epoch 57/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1588\n",
            "Epoch 58/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1580\n",
            "Epoch 59/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1573\n",
            "Epoch 60/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1567\n",
            "Epoch 61/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1561\n",
            "Epoch 62/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1557\n",
            "Epoch 63/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1552\n",
            "Epoch 64/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1548\n",
            "Epoch 65/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1545\n",
            "Epoch 66/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1541\n",
            "Epoch 67/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1538\n",
            "Epoch 68/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1535\n",
            "Epoch 69/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1532\n",
            "Epoch 70/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1530\n",
            "Epoch 71/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1527\n",
            "Epoch 72/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1526\n",
            "Epoch 73/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1524\n",
            "Epoch 74/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1522\n",
            "Epoch 75/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1520\n",
            "Epoch 76/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1518\n",
            "Epoch 77/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1517\n",
            "Epoch 78/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1515\n",
            "Epoch 79/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1514\n",
            "Epoch 80/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1513\n",
            "Epoch 81/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1511\n",
            "Epoch 82/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1510\n",
            "Epoch 83/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1509\n",
            "Epoch 84/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1507\n",
            "Epoch 85/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1507\n",
            "Epoch 86/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1505\n",
            "Epoch 87/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1504\n",
            "Epoch 88/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1503\n",
            "Epoch 89/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1502\n",
            "Epoch 90/200\n",
            "341/341 [==============================] - 30s 85ms/step - loss: 0.1502\n",
            "Epoch 91/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1500\n",
            "Epoch 92/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1499\n",
            "Epoch 93/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1499\n",
            "Epoch 94/200\n",
            "341/341 [==============================] - 30s 86ms/step - loss: 0.1498\n",
            "Epoch 00094: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW9l1MCJfGOg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c4ac6814-5ae0-45cc-ddf7-95f9da4bae51"
      },
      "source": [
        "loss_plot(history_lstm)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FZ6OpOLgFNY"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    return predicted_chars, states"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt3HYqHxK5A7"
      },
      "source": [
        "one_step_model = OneStep(lstm_model_2, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwW6FHz4gK07",
        "outputId": "7f572157-c289-49ab-c953-6e256cfcdc8d"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "I have night's cloak to hide me from their speech,\n",
            "And never brand by the nose which Longon\n",
            "Wis cold to sort a good white:\n",
            "I will not budghen out of parison, and your solemn torserves\n",
            "Which five hash that purposed my heart to thee and badest than till\n",
            "The run but worth of death.\n",
            "\n",
            "SEBASTIAN:\n",
            "With all my heart as you shall find\n",
            "me yare; for truly, sir, for your brother's death.\n",
            "\n",
            "BALTARAT:\n",
            "Thank, for this good Coriolanus 'head him a tombor's friend\n",
            "And then take order them with all crown'd\n",
            "worthy with a gentlemanly shamen to him.\n",
            "\n",
            "Shepherd:\n",
            "And so have I, by the wager be't in my a time was ever peace\n",
            "To sinner Vincentio.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill my brother; we will unto the occident,\n",
            "Which, without contrived in soothing men, you know\n",
            "Our sorrow'd life in house of his mellow\n",
            "And heap it all answering beauty served and fresh.\n",
            "\n",
            "GREGORY:\n",
            "The hate physicing souls have heard him stay.\n",
            "Trive me there, my gracious lord, expecially affeir.\n",
            "\n",
            "ANGELO:\n",
            "Good night.\n",
            "This deed unbound to this entranc \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.218057870864868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meQ88R2qKmZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614aaaca-03ff-4141-87cd-b3e3e4cf82d9"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nAlas, that 'outish'd, my companion is the stroke\\nBetween the life that trembled upon this world,\\nAs scarish'd, my soul is not hath knock'd and swore.\\n\\nBRUTUS:\\nNot possible.\\n\\nCORIOLANUS:\\nWhat is this?\\nYour purse is not Rome back to your young prince.\\n\\nKING EDWARD IV:\\nWell, jest on, bring me to her her.\\n\\nLADY CAPULET:\\nFie, freely I wish you not.\\n\\nJULIET:\\nThe king did for a thing when thou art experity.\\nBut what talk I of Antigonus,' and Master\\ncoust, as I can devise, I am a book for Rome, and one than to live\\nTo murder me and to my ward through our levies, now in again thy face,\\nThat gives not himself on Tarpeige betwixt you thanks.\\n\\nKING EDWARD IV:\\nBishop or what thou hast marr'd, this world but zell in earth.\\n\\nBAPTISTA:\\nWho comes with your honour with him! he will return before\\nHis tears do plot them and then lay in my days would behold\\nThe stern you find on herself.\\n\\nGLOUCESTER:\\nMy lord, some have I scold to strike all this goodly rept;\\nSuspicious it excelsed against my word,\\nAnd see\"\n",
            " b\"ROMEO:\\nAlas, that love, whose view is muffled still\\nTo see a Jack, that thou hast done a friend\\nAnd almost to ann loath, not stain the time;\\nAnd bid her death hath shed forth love, her sacred heapt,\\nThe fair reverence of the court-will we give out power than the absent time\\nAfter the rest of these articles.\\n\\nMONTAGUE:\\nAut, when this arm up wind with off befatter with child\\nA gentle shall be the actor of hostels of the action.\\n\\nSecond Gensleman:\\nI never hear no more: thou'rt long'st not so bared and beseech you\\nAn old harm and that thou art malience.\\n\\nKING RICHARD II:\\nRode he go the prisoner?\\n\\nNurse:\\nO Lord, I could see no house to France and such a silly pace\\nWith Roperment of slander to your daughter.\\n\\nLADY CAPULET:\\nI would they were abount?\\n\\nMessenger:\\nAy, sir; so the duke sharp to the begin.\\n\\nAUTOLYCUS:\\nAdieu, peace!\\nthou shalt be master for being a barbe:\\nsound the cause of what doth comfort\\nShall I wash you not?\\n\\nESCALUS:\\n\\nHASTINGS:\\nTo Lend forthomity in the sun under the doI.\\n\\nPETRUCHI\"\n",
            " b\"ROMEO:\\nI have night's cloak to hide me from their speech\\nAs is the bilation. What sorrow is this thunder? where have you\\nTo see her Richmond traniot is she told the man.\\n\\nLord Marshal:\\nSound, sound, sound!\\nSpeak not for these great justice of this slander.\\n\\nSICINIUS:\\nDo they love her: I have true, my lord.\\n\\nKING RICHARD III:\\nO Ratcliff, most royal, for I know this woman.\\n\\nPETRUCHIO:\\nWhat say you that is nothing hold, what would you say?\\n\\nISABELLA:\\nIn boundeous lord,\\nMust give look and night: and this is writ hen visiting them\\nAnd free from other for the glass, where thou shalt not scape at his nation.\\nBut heaven hath that alived in Posinies,\\nWhen it is as broach, so bloody on our ancient,\\nYet call for a hermed with the fearful at the highway:\\nbeathering who even in the chiefest hold\\nthan of them reason whilst his head and holy of your behalf,\\nAnd bear her beauty treasune and the best;\\nThe very revellion an others of a foot,\\nDid keep the seath of the noble Vouchsafe and a soldier.\\nTherefore y\"\n",
            " b\"ROMEO:\\nI have night's cloak to hide me from their speech\\nThat lies bear the swelving dimf a loyal friends,\\n'Tis full three that way'd of my poor brother's.\\nWithin the heavy man! Ralane! it is a man's\\nNoverty as his seat come to me again to leap the man\\nThat bears the tyrant that hook how he might be understood\\nThe one side mistrusting for that word's day:\\nFor I have had no more merely to swear the silly trif\\nAnd kind to be his subject.\\n\\nKING RICHARD III:\\nWrong not, grief makes this suits aring?\\n\\nLUCIO:\\nI pray she may; as well for the encouragement,\\nYou do him good for it: you do report whatever I\\nhave this so hit in this careless of your hearing: he is all the pocket\\nWhich you at the father with his enemies.\\n\\nMARCIUS:\\nI think they are at it; and it is\\ncurred him and no slaughters and her father is an hour\\nAnd here at hand: it dides himself, please my father,\\nMake great Angelo is port without atay,\\nA marbor of my bliss and coming;\\nBut as this thought depose,\\nWe should infringe the holy and ma\"\n",
            " b\"ROMEO:\\nA gentleman, and so began to-day;\\nAnd this ready to go to strike all this?\\n\\nBIANCA:\\nMethinks a king, we'll succor them as the fire,\\nNor England all things shalt still be cool'd to so,\\nI swear, my lord, is gone to hieve my parent.\\n\\nMIRANDA:\\nMy raimed is too long to see this house.\\n\\nPETRUCHIO:\\nThy gown? why, ay: come, tailor.\\n\\nGEORGE:\\nWell, well, he was the covert's face of mine ears.\\n\\nWARWICK:\\nAnd I the house with smile, as well the field,\\nSelf and all allegs in him. You are therein beholding!\\n\\nBIONDELLO:\\nThe bloody parasate as thy cold beauty,\\nAs if that did put your enemy\\nTo see him any more,--casorant dream,\\nUnless they have made service what he look'd upon\\nOr hand of money boss than hanging.\\n\\nDUKE VINCENTIO:\\nYou shall not reason very touches of banish'd with a mortal to the Tower.\\n\\nKING EDWARD IV:\\nSee that he be not, I beseech your grace to hear him out:\\nBelieve me, like a truth how to use as mine hath.\\n\\nYORK:\\nI shall keep her simple Physician from his ease,\\nBut by so be crutch'd i\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 6.083287477493286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNrn7PQTgIYk"
      },
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4qdTwQfiGAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b64134-6127-4b6d-e0b8-5e65ce55d3ca"
      },
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "I have night's cloak to hide me from their sprites;\n",
            "But for the world were hand no less than ever:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}